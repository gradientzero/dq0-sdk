{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQ0 SDK / CLI Demo\n",
    "## Prerequistes\n",
    "* Installed DQ0 SDK. Install with `pip install dq0sdk`\n",
    "* Installed DQ0 CLI.\n",
    "* Proxy running and registered from the DQ0 CLI with `dq0-cli proxy add ...`\n",
    "* Valid session of DQ0. Log in with `dq0 auth login`\n",
    "* Running instance of DQ0 CLI server: `dq0 server start`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept\n",
    "The two main structures to work with DQ0 quarantine via the DQ0 SDK are\n",
    "* Project - the current model environment, a workspace and directory the user can define models in. Project also provides access to trained models.\n",
    "* Experiment - the DQ0 runtime to execute training runs in the remote quarantine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the core classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dq0sdk cli\n",
    "from dq0sdk.cli import Project, Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "Projects act as the working environment for model development.\n",
    "Each project has a model directory with a .meta file containing the model uuid, attached data sources etc.\n",
    "Creating a project with `Project.create(name='model_1')` is equivalent to calling the DQ0 Cli command `dq0-cli model create --name model_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a project with name 'model_1'. Automatically creates the 'model_1' directory and changes to this directory.\n",
    "project = Project(name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a project\n",
    "Alternatively, you can load an existing project by first cd'ing into this directory and then call Project.load()\n",
    "This will read in the .meta file of this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: load a project from the current model directory\n",
    "project = Project.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "To execute DQ0 training commands inside the quarantine you define experiments for your projects.\n",
    "You can create as many experiments as you like for one project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment for project\n",
    "experiment = Experiment(project=project, name='experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and attach data source\n",
    "For new projects you need to attach a data source. Existing (loaded) projects usually already have data sources attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get some info about available data sources\n",
    "sources = project.get_available_data_sources()\n",
    "\n",
    "# print info abouth the first source\n",
    "info = project.get_data_info(sources[0]['uuid'])\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data description\n",
    "info['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, inspect the data column types including allowed values for feature generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print information about column types and values\n",
    "info['types']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some sample data if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample data\n",
    "project.get_sample_data(sources[0]['uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, attach the dataset to our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the first dataset\n",
    "project.attach_data_source(sources[0]['uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "Working with DQ0 is basically about defining two functions:\n",
    "* setup_data() - called right before model training to prepare attached data sources\n",
    "* setup_model() - actual model definition code\n",
    "The easiest way to define those functions is to write them in the notebook (inline) and pass them to the project before calling deploy. Alternatively, the user can write the complete user_model.py to the project's directory.\n",
    "\n",
    "### Define fuctions inline\n",
    "First variant with functions passed to the project instance. Note that you need to define imports inline inside the functions as only those code blocks are replaced in the source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def setup_data():\n",
    "    # load input data\n",
    "    if self.data_source is None:\n",
    "        logger.error('No data source found')\n",
    "        return\n",
    "\n",
    "    data = self.data_source.read()\n",
    "\n",
    "    # read and preprocess the data\n",
    "    dataset_df = self.preprocess()\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train_df, X_test_df, y_train_ts, y_test_ts =\\\n",
    "        train_test_split(dataset_df.iloc[:, :-1],\n",
    "                         dataset_df.iloc[:, -1],\n",
    "                         test_size=0.33,\n",
    "                         random_state=42)\n",
    "    self.input_dim = X_train_df.shape[1]\n",
    "\n",
    "    # set data member variables\n",
    "    self.X_train = X_train_df\n",
    "    self.X_test = X_test_df\n",
    "    self.y_train = y_train_ts\n",
    "    self.y_test = y_test_ts\n",
    "    \n",
    "def setup_model():\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    self.learning_rate = 0.1\n",
    "    self.epochs = 10\n",
    "    # self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "    self.optimizer = 'Adam'\n",
    "    self.model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(self.input_dim),\n",
    "        tf.keras.layers.Dense(10, activation='tanh'),\n",
    "        tf.keras.layers.Dense(10, activation='tanh'),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')])\n",
    "    \n",
    "def preprocess():\n",
    "    # columns\n",
    "    column_names_list = [\n",
    "        'lastname',\n",
    "        'firstname',\n",
    "        'age',\n",
    "        'workclass',\n",
    "        'fnlwgt',\n",
    "        'education',\n",
    "        'education-num',\n",
    "        'marital-status',\n",
    "        'occupation',\n",
    "        'relationship',\n",
    "        'race',\n",
    "        'sex',\n",
    "        'capital-gain',\n",
    "        'capital-loss',\n",
    "        'hours-per-week',\n",
    "        'native-country',\n",
    "        'income'\n",
    "    ]\n",
    "\n",
    "    # columns types list drawn from data source types information above.\n",
    "    columns_types_list = [\n",
    "        {\n",
    "            'name': 'age',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'workclass',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Private',\n",
    "                'Self-emp-not-inc',\n",
    "                'Self-emp-inc',\n",
    "                'Federal-gov',\n",
    "                'Local-gov',\n",
    "                'State-gov',\n",
    "                'Without-pay',\n",
    "                'Never-worked',\n",
    "                'Unknown'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'fnlwgt',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'education',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Bachelors',\n",
    "                'Some-college',\n",
    "                '11th',\n",
    "                'HS-grad',\n",
    "                'Prof-school',\n",
    "                'Assoc-acdm',\n",
    "                'Assoc-voc',\n",
    "                '9th',\n",
    "                '7th-8th',\n",
    "                '12th',\n",
    "                'Masters',\n",
    "                '1st-4th',\n",
    "                '10th',\n",
    "                'Doctorate',\n",
    "                '5th-6th',\n",
    "                'Preschool'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'education-num',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'marital-status',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Married-civ-spouse',\n",
    "                'Divorced',\n",
    "                'Never-married',\n",
    "                'Separated',\n",
    "                'Widowed',\n",
    "                'Married-spouse-absent',\n",
    "                'Married-AF-spouse'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'occupation',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Tech-support',\n",
    "                'Craft-repair',\n",
    "                'Other-service',\n",
    "                'Sales',\n",
    "                'Exec-managerial',\n",
    "                'Prof-specialty',\n",
    "                'Handlers-cleaners',\n",
    "                'Machine-op-inspct',\n",
    "                'Adm-clerical',\n",
    "                'Farming-fishing',\n",
    "                'Transport-moving',\n",
    "                'Priv-house-serv',\n",
    "                'Protective-serv',\n",
    "                'Armed-Forces',\n",
    "                'Unknown'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'relationship',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Wife',\n",
    "                'Own-child',\n",
    "                'Husband',\n",
    "                'Not-in-family',\n",
    "                'Other-relative',\n",
    "                'Unmarried'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'race',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'White',\n",
    "                'Asian-Pac-Islander',\n",
    "                'Amer-Indian-Eskimo',\n",
    "                'Other',\n",
    "                'Black'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'sex',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Female',\n",
    "                'Male'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'capital-gain',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'capital-loss',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'hours-per-week',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'native-country',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'United-States',\n",
    "                'Cambodia',\n",
    "                'England',\n",
    "                'Puerto-Rico',\n",
    "                'Canada',\n",
    "                'Germany',\n",
    "                'Outlying-US(Guam-USVI-etc)',\n",
    "                'India',\n",
    "                'Japan',\n",
    "                'Greece',\n",
    "                'South',\n",
    "                'China',\n",
    "                'Cuba',\n",
    "                'Iran',\n",
    "                'Honduras',\n",
    "                'Philippines',\n",
    "                'Italy',\n",
    "                'Poland',\n",
    "                'Jamaica',\n",
    "                'Vietnam',\n",
    "                'Mexico',\n",
    "                'Portugal',\n",
    "                'Ireland',\n",
    "                'France',\n",
    "                'Dominican-Republic',\n",
    "                'Laos',\n",
    "                'Ecuador',\n",
    "                'Taiwan',\n",
    "                'Haiti',\n",
    "                'Columbia',\n",
    "                'Hungary',\n",
    "                'Guatemala',\n",
    "                'Nicaragua',\n",
    "                'Scotland',\n",
    "                'Thailand',\n",
    "                'Yugoslavia',\n",
    "                'El-Salvador',\n",
    "                'Trinadad&Tobago',\n",
    "                'Peru',\n",
    "                'Hong',\n",
    "                'Holand-Netherlands',\n",
    "                'Unknown'\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    from dq0sdk.data.preprocessing import preprocessing\n",
    "    import sklearn.preprocessing\n",
    "    import pandas as pd\n",
    "\n",
    "    if 'dataset' in globals():\n",
    "        # local testing mode\n",
    "        dataset = globals()['dataset']\n",
    "    else:\n",
    "        # get the input dataset\n",
    "        if self.data_source is None:\n",
    "            logger.error('No data source found')\n",
    "            return\n",
    "\n",
    "        # read the data via the attached input data source\n",
    "        dataset = self.data_source.read(\n",
    "            names=column_names_list,\n",
    "            sep=',',\n",
    "            skiprows=1,\n",
    "            index_col=None,\n",
    "            skipinitialspace=True,\n",
    "            na_values={\n",
    "                'capital-gain': 99999,\n",
    "                'capital-loss': 99999,\n",
    "                'hours-per-week': 99,\n",
    "                'workclass': '?',\n",
    "                'native-country': '?',\n",
    "                'occupation': '?'}\n",
    "        )\n",
    "\n",
    "    # drop unused columns\n",
    "    dataset.drop(['lastname', 'firstname'], axis=1, inplace=True)\n",
    "    column_names_list.remove('lastname')\n",
    "    column_names_list.remove('firstname')\n",
    "\n",
    "    # define target feature\n",
    "    target_feature = 'income'\n",
    "\n",
    "    # get categorical features\n",
    "    categorical_features_list = [\n",
    "        col['name'] for col in columns_types_list\n",
    "        if col['type'] == 'string']\n",
    "\n",
    "    # get categorical features\n",
    "    quantitative_features_list = [\n",
    "        col['name'] for col in columns_types_list\n",
    "        if col['type'] == 'int' or col['type'] == 'float']\n",
    "\n",
    "    # get arguments\n",
    "    approach_for_missing_feature = 'imputation'\n",
    "    imputation_method_for_cat_feats = 'unknown'\n",
    "    imputation_method_for_quant_feats = 'median'\n",
    "    features_to_drop_list = None\n",
    "\n",
    "    # handle missing data\n",
    "    dataset = preprocessing.handle_missing_data(\n",
    "        dataset,\n",
    "        mode=approach_for_missing_feature,\n",
    "        imputation_method_for_cat_feats=imputation_method_for_cat_feats,\n",
    "        imputation_method_for_quant_feats=imputation_method_for_quant_feats,  # noqa: E501\n",
    "        categorical_features_list=categorical_features_list,\n",
    "        quantitative_features_list=quantitative_features_list)\n",
    "\n",
    "    if features_to_drop_list is not None:\n",
    "        dataset.drop(features_to_drop_list, axis=1, inplace=True)\n",
    "\n",
    "    # get dummy columns\n",
    "    dataset = pd.get_dummies(dataset, columns=categorical_features_list, dummy_na=False)    \n",
    "\n",
    "    # unzip categorical features with dummies\n",
    "    categorical_features_list_with_dummies = []\n",
    "    for col in columns_types_list:\n",
    "        if col['type'] == 'string':\n",
    "            for value in col['values']:\n",
    "                categorical_features_list_with_dummies.append('{}_{}'.format(col['name'], value))\n",
    "\n",
    "    # add missing columns\n",
    "    missing_columns = set(categorical_features_list_with_dummies) - set(dataset.columns)\n",
    "    for col in missing_columns:\n",
    "        dataset[col] = 0\n",
    "        \n",
    "    # and sort the columns\n",
    "    dataset = dataset.reindex(sorted(dataset.columns), axis=1)\n",
    "\n",
    "    # Scale values to the range from 0 to 1 to be precessed by the neural network\n",
    "    dataset[quantitative_features_list] = sklearn.preprocessing.minmax_scale(dataset[quantitative_features_list])\n",
    "\n",
    "    # label target\n",
    "    y_ts = dataset[target_feature]\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    y_bin_nb = le.fit_transform(y_ts)\n",
    "    y_bin = pd.Series(index=y_ts.index, data=y_bin_nb)\n",
    "    dataset.drop([target_feature], axis=1, inplace=True)\n",
    "    dataset[target_feature] = y_bin\n",
    "\n",
    "    return dataset\n",
    "    \n",
    "# set model code in project\n",
    "project.set_model_code(setup_data=setup_data, setup_model=setup_model, preprocess=preprocess, parent_class_name='NeuralNetworkClassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions as source code\n",
    "Second variant, writing the complete model. Template can be retrieved by `!cat models/user_model.py` which is created by Project create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/user_model.py\n",
    "\n",
    "import logging\n",
    "\n",
    "from dq0sdk.models.tf.neural_network_classification import NeuralNetworkClassification\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class UserModel(NeuralNetworkClassification):\n",
    "    \"\"\"Derived from dq0sdk.models.tf.NeuralNetwork class\n",
    "\n",
    "    Model classes provide a setup method for data and model\n",
    "    definitions.\n",
    "\n",
    "    Args:\n",
    "        model_path (:obj:`str`): Path to the model save destination.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__(model_path)\n",
    "\n",
    "    def setup_data(self):\n",
    "        \"\"\"Setup data function. See code above...\"\"\"\n",
    "        pass\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Preprocess the data. See code above...\"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup model function See code above...\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "After testing the model locally directly in this notebook, it's time to train it inside the DQ0 quarantine. This is done by calling experiment.train() which in turn calls the Cli commands `dq0-cli model deploy` and `dq0-cli model train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is executed asynchronously. You can wait for the run to complete or get the state with get_state:\n",
    "(TBD: in the future there could by a jupyter extension that shows the run progress in a widget.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for completion\n",
    "run.wait_for_completion(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the run has completed you can retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training results\n",
    "print(run.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After train dq0 will run the model checker to evaluate if the trained model is safe and allowed for prediction. Get the state of the checker run together with the other state information with the get_state() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the state whenever you like\n",
    "print(run.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Finally, it's time to use the trained model to predict something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# get the latest model\n",
    "model = project.get_latest_model()\n",
    "\n",
    "# check DQ0 privacy clearing\n",
    "if model.predict_allowed:\n",
    "\n",
    "    # create predict set\n",
    "    records = [\n",
    "        {\n",
    "            'lastname': 'some-lastname',\n",
    "            'firstname': 'some-firstname',\n",
    "            'age': 45,\n",
    "            'workclass':'Private',\n",
    "            'fnlwgt': 544091,\n",
    "            'education': 'HS-grad',\n",
    "            'education-num': 9,\n",
    "            'marital-status': 'Married-AF-spouse',\n",
    "            'occupation': 'Exec-managerial',\n",
    "            'relationship': 'Wife',\n",
    "            'race': 'White',\n",
    "            'sex': 'Female',\n",
    "            'capital-gain': 0,\n",
    "            'capital-loss': 0,\n",
    "            'hours-per-week': 25,\n",
    "            'native-country': 'United-States',\n",
    "            'income': '<=50K'\n",
    "        },\n",
    "        {\n",
    "            'lastname': 'some-lastname',\n",
    "            'firstname': 'some-firstname',\n",
    "            'age': 29,\n",
    "            'workclass': 'Federal-gov',\n",
    "            'fnlwgt': 162298,\n",
    "            'education': 'Masters',\n",
    "            'education-num': 14,\n",
    "            'marital-status': 'Married-civ-spouse',\n",
    "            'occupation': 'Exec-managerial',\n",
    "            'relationship': 'Husband',\n",
    "            'race': 'White',\n",
    "            'sex': 'Male',\n",
    "            'capital-gain': 34084,\n",
    "            'capital-loss': 0,\n",
    "            'hours-per-week': 70,\n",
    "            'native-country': 'United-States',\n",
    "            'income': '<=50K'\n",
    "        }\n",
    "    ]\n",
    "    dataset = pd.DataFrame.from_records(records)\n",
    "    \n",
    "    # preprocess data\n",
    "    dataset = preprocess()\n",
    "    \n",
    "    # drop target (included above only because of compatability with preprocess function)\n",
    "    dataset.drop(['income'], axis=1, inplace=True)\n",
    "\n",
    "    # load or get numpy predict data\n",
    "    # predict_data = np.load(‘X_demo_predict.npy’)\n",
    "    predict_data = dataset.to_numpy()\n",
    "\n",
    "    # call predict\n",
    "    run = model.predict(predict_data)\n",
    "\n",
    "    # wait for completion\n",
    "    run.wait_for_completion(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predict results\n",
    "print(run.get_results()['predict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
