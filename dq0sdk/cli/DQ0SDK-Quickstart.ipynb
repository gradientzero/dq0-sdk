{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQ0 SDK / CLI Demo\n",
    "## Prerequistes\n",
    "* Installed DQ0 SDK. Install with `pip install dq0sdk`\n",
    "* Proxy running and registered from the DQ0 CLI with `dq0-cli proxy add ...`\n",
    "* Valid session of DQ0. Log in with `dq0 auth login`\n",
    "\n",
    "To communicate with the DQ0 instance the DQ0 CLI Server needs be running.\n",
    "Change to the directory of your DQ0 CLI installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /path/to/your/cli/installation/cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start the server with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "proc = subprocess.Popen(['./dq0', 'server', 'start'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept\n",
    "The two main structures to work with DQ0 quarantine via the DQ0 SDK are\n",
    "* Project - the current model environment, a workspace and directory the user can define models in. Project also provides access to trained models.\n",
    "* Experiment - the DQ0 runtime to execute training runs in the remote quarantine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the core classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dq0sdk cli\n",
    "from dq0sdk.cli import Project, Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "Projects act as the working environment for model development.\n",
    "Each project has a model directory with a .meta file containing the model uuid, attached data sources etc.\n",
    "Creating a project with `Project.create(name='model_1')` is equivalent to calling the DQ0 Cli command `dq0-cli model create --name model_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a project with name 'model_1'. Automatically creates the 'model_1' directory and changes to this directory.\n",
    "project = Project(name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a project\n",
    "Alternatively, you can load an existing project by first cd'ing into this directory and then call Project.load()\n",
    "This will read in the .meta file of this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: load a project from the current model directory\n",
    "project = Project.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "To execute DQ0 training commands inside the quarantine you define experiments for your projects.\n",
    "You can create as many experiments as you like for one project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment for project\n",
    "experiment = Experiment(project=project, name='experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or attach data source\n",
    "For new projects you need to attach a data source. Existing (loaded) projects usually already have data sources attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of available data sources\n",
    "sources = project.get_available_data_sources()\n",
    "\n",
    "# attach the first dataset\n",
    "project.attach_data_source(sources[0]['UUID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "Working with DQ0 is basically about defining two functions:\n",
    "* setup_data() - called right before model training to prepare attached data sources\n",
    "* setup_model() - actual model definition code\n",
    "The easiest way to define those functions is to write them in the notebook (inline) and pass them to the project before calling deploy. Alternatively, the user can write the complete user_model.py to the project's directory.\n",
    "\n",
    "### Define fuctions inline\n",
    "First variant with functions passed to the project instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def setup_data():\n",
    "    # load data\n",
    "    if len(self.data_sources) < 1:\n",
    "        logger.error('No data source found')\n",
    "        return\n",
    "    source = next(iter(self.data_sources.values()))\n",
    "\n",
    "    data = source.read()\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train_df, X_test_df, y_train_ts, y_test_ts =\\\n",
    "        train_test_split(data.iloc[:, :-1],\n",
    "                         data.iloc[:, -1],\n",
    "                         test_size=0.33,\n",
    "                         random_state=42)\n",
    "    self.input_dim = X_train_df.shape[1]\n",
    "\n",
    "    # set data member variables\n",
    "    self.X_train = X_train_df\n",
    "    self.X_test = X_test_df\n",
    "    self.y_train = y_train_ts\n",
    "    self.y_test = y_test_ts\n",
    "    \n",
    "def setup_model():\n",
    "    from tensorflow import keras\n",
    "    self.learning_rate = 0.3\n",
    "    self.epochs = 5\n",
    "    self.num_microbatches = 1\n",
    "    self.model = keras.Sequential([\n",
    "        keras.layers.Input(self.input_dim),\n",
    "        keras.layers.Dense(10, activation='tanh'),\n",
    "        keras.layers.Dense(10, activation='tanh'),\n",
    "        keras.layers.Dense(2, activation='softmax')])\n",
    "    \n",
    "def preprocess():\n",
    "    # some data preprocessing\n",
    "    pass\n",
    "    \n",
    "# set model code in project\n",
    "project.set_model_code(setup_data=setup_data, setup_model=setup_model, parent_class_name='NeuralNetwork')\n",
    "\n",
    "# set data code in project\n",
    "project.set_data_code(preprocess=preprocess, parent_class_name='CSVSource')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions as source code\n",
    "Second variant, writing the complete model. Template can be retrieved by `!cat models/user_model.py` which is created by Project create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/user_model.py\n",
    "\n",
    "import logging\n",
    "\n",
    "from dq0sdk.models.tf.neural_network import NeuralNetwork\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class UserModel(NeuralNetwork):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__(model_path)\n",
    "        self.learning_rate = 0.3\n",
    "        self.epochs = 5\n",
    "        self.num_microbatches = 1\n",
    "        self.verbose = 0\n",
    "        self.metrics = ['accuracy', 'mse']\n",
    "        self.input_dim = None\n",
    "\n",
    "    def setup_data(self):\n",
    "        # load data\n",
    "        if len(self.data_sources) < 1:\n",
    "            logger.error('No data source found')\n",
    "            return\n",
    "        source = next(iter(self.data_sources.values()))\n",
    "\n",
    "        data = source.read()\n",
    "\n",
    "        X_train_df, X_test_df, y_train_ts, y_test_ts =\\\n",
    "            train_test_split(data.iloc[:, :-1],\n",
    "                             data.iloc[:, -1],\n",
    "                             test_size=0.33,\n",
    "                             random_state=42)\n",
    "        self.input_dim = X_train_df.shape[1]\n",
    "\n",
    "        # set data member variables\n",
    "        self.X_train = X_train_df\n",
    "        self.X_test = X_test_df\n",
    "        self.y_train = y_train_ts\n",
    "        self.y_test = y_test_ts\n",
    "\n",
    "    def setup_model(self):\n",
    "        self.model = keras.Sequential([\n",
    "            keras.layers.Input(self.input_dim),\n",
    "            keras.layers.Dense(10, activation='tanh'),\n",
    "            keras.layers.Dense(10, activation='tanh'),\n",
    "            keras.layers.Dense(2, activation='softmax')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for data/user_source.py to define the preprocess() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "After testing the model locally directly in this notebook, it's time to train it inside the DQ0 quarantine. This is done by calling experiment.train() which in turn calls the Cli commands `dq0-cli model deploy` and `dq0-cli model train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is executed asynchronously. You can wait for the run to complete or get the state with get_state:\n",
    "(TBD: in the future there could by a jupyter extension that shows the run progress in a widget.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for completion\n",
    "run.wait_for_completion(verbose=True)\n",
    "\n",
    "# or get the state whenever you like\n",
    "print(run.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the run has completed you can retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training results\n",
    "print(run.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Finally, it's time to use the trained model to predict something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get the latest model\n",
    "model = project.get_latest_model()\n",
    "\n",
    "# check DQ0 privacy clearing\n",
    "if model.predict_allowed:\n",
    "\n",
    "    # call predict\n",
    "    run = model.predict(np.array([1, 2, 3]))\n",
    "\n",
    "    # wait for completion\n",
    "    run.wait_for_completion(verbose=True)\n",
    "\n",
    "    # get training results\n",
    "    print(run.get_results())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
