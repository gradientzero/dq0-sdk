{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQ0 SDK Demo\n",
    "## Prerequistes\n",
    "* Installed DQ0 SDK. Install with `pip install dq0-sdk`\n",
    "* Installed DQ0 CLI.\n",
    "* Proxy running and registered from the DQ0 CLI with `dq0-cli proxy add ...`\n",
    "* Valid session of DQ0. Log in with `dq0 user login`\n",
    "* Running instance of DQ0 CLI server: `dq0 server start`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept\n",
    "The two main structures to work with DQ0 quarantine via the DQ0 SDK are\n",
    "* Project - the current model environment, a workspace and directory the user can define models in. Project also provides access to trained models.\n",
    "* Experiment - the DQ0 runtime to execute training runs in the remote quarantine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the core classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dq0-sdk cli\n",
    "from dq0.sdk.cli import Project, Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "Projects act as the working environment for model development.\n",
    "Each project has a model directory with a .meta file containing the model uuid, attached data sources etc.\n",
    "Creating a project with `Project.create(name='model_1')` is equivalent to calling the DQ0 Cli command `dq0-cli project create model_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a project with name 'model_1'. Automatically creates the 'model_1' directory and changes to this directory.\n",
    "project = Project(name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a project\n",
    "Alternatively, you can load an existing project by first cd'ing into this directory and then call Project.load()\n",
    "This will read in the .meta file of this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: load a project from the current model directory\n",
    "project = Project.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "To execute DQ0 training commands inside the quarantine you define experiments for your projects.\n",
    "You can create as many experiments as you like for one project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment for project\n",
    "experiment = Experiment(project=project, name='experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and attach data source\n",
    "For new projects you need to attach a data source. Existing (loaded) projects usually already have data sources attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get some info about available data sources\n",
    "sources = project.get_available_data_sources()\n",
    "\n",
    "# print info abouth the first source\n",
    "info = project.get_data_info(sources[0]['uuid'])\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data description\n",
    "info['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, inspect the data column types including allowed values for feature generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print information about column types and values\n",
    "info['types']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some sample data if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample data\n",
    "project.get_sample_data(sources[0]['uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, attach the dataset to our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the first dataset\n",
    "project.attach_data_source(sources[0]['uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a convolutional neural network for the Cifar-10 image data\n",
    "Working with DQ0 is basically about defining two functions:\n",
    "* setup_data() - called right before model training to prepare attached data sources\n",
    "* setup_model() - actual model definition code\n",
    "The easiest way to define those functions is to write them in the notebook (inline) and pass them to the project before calling deploy. Alternatively, the user can write the complete user_model.py to the project's directory.\n",
    "\n",
    "### Define fuctions inline\n",
    "First variant with functions passed to the project instance. Note that you need to define imports inline inside the functions as only those code blocks are replaced in the source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def setup_data(self):\n",
    "    # load input data\n",
    "    if self.data_source is None:\n",
    "        logger.error('No data source found')\n",
    "        return\n",
    "\n",
    "    X, y = self.data_source.read()\n",
    "\n",
    "    # check data format\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    else:\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise Exception('X is not np.ndarray')\n",
    "\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.values\n",
    "    else:\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise Exception('y is not np.ndarray')\n",
    "\n",
    "    # prepare data\n",
    "    if y.ndim == 2:\n",
    "        # make non-dimensional array (just to avoid Warnings by Sklearn)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    self._num_classes = len(np.unique(y))  # np.nan, np.Inf in y are \n",
    "    # counted as classes by np.unique\n",
    "\n",
    "    # encodes target labels with interger values between 0 and \n",
    "    # self._num_classes - 1\n",
    "    self.label_encoder = LabelEncoder()\n",
    "    y = self.label_encoder.fit_transform(y)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    # back to column vector: transform one-dimensional array into column vector\n",
    "    y_train = y_train[:, np.newaxis]\n",
    "    y_test = y_test[:, np.newaxis]\n",
    "    \n",
    "    # set data member variables\n",
    "    self.X_train = X_train\n",
    "    self.X_test = X_test\n",
    "    self.y_train = y_train\n",
    "    self.y_test = y_test\n",
    "\n",
    "\n",
    "def setup_model(self):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    self.optimizer = 'Adam'\n",
    "    # To set optimizer parameters, instantiate the class:\n",
    "    #   self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    self.metrics = ['accuracy']\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    # As an alternative, define the loss function with a string\n",
    "    self.epochs = 50\n",
    "    self.batch_size = 250\n",
    "    regularization_param = 1e-3\n",
    "    regularizer_dict = {\n",
    "        'kernel_regularizer': tf.keras.regularizers.l2(regularization_param)\n",
    "    }\n",
    "\n",
    "    self.model = tf.keras.Sequential()\n",
    "\n",
    "    # generate convolutional and pooling layers\n",
    "    self.model.add(tf.keras.layers.Conv2D(32, (5, 5), activation='relu',\n",
    "                   input_shape=(32, 32, 3), **regularizer_dict))\n",
    "    self.model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    self.model.add(tf.keras.layers.Conv2D(32, (5, 5), activation='relu',\n",
    "                   **regularizer_dict))\n",
    "    self.model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # stack fully-connected (aka dense) layers on top\n",
    "    self.model.add(tf.keras.layers.Flatten())\n",
    "    self.model.add(tf.keras.layers.Dense(128, activation='tanh', **regularizer_dict))\n",
    "    self.model.add(tf.keras.layers.Dense(self._num_classes, activation='softmax'))\n",
    "\n",
    "    self.model.summary()\n",
    "\n",
    "\n",
    "# set model code in project\n",
    "project.set_model_code(setup_data=setup_data, setup_model=setup_model, \n",
    "                       parent_class_name='NeuralNetworkClassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions as source code\n",
    "Second variant, writing the complete model. Template can be retrieved by `!cat models/user_model.py` which is created by Project create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/user_model.py\n",
    "\n",
    "import logging\n",
    "\n",
    "from dq0.sdk.models.tf import NeuralNetworkClassification\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class UserModel(NeuralNetworkClassification):\n",
    "    \"\"\"Derived from dq0.sdk.models.tf.NeuralNetwork class\n",
    "\n",
    "    Model classes provide a setup method for data and model\n",
    "    definitions.\n",
    "\n",
    "    Args:\n",
    "        model_path (:obj:`str`): Path to the model save destination.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__(model_path)\n",
    "\n",
    "    def setup_data(self):\n",
    "        \"\"\"Setup data function. See code above...\"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup model function See code above...\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "After testing the model locally directly in this notebook, it's time to train it inside the DQ0 quarantine. This is done by calling experiment.train() which in turn calls the Cli commands `dq0-cli project deploy` and `dq0-cli model train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is executed asynchronously. You can wait for the run to complete or get the state with get_state:\n",
    "(TBD: in the future there could by a jupyter extension that shows the run progress in a widget.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for completion\n",
    "run.wait_for_completion(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the run has completed you can retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training results\n",
    "print(run.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After train dq0 will run the model checker to evaluate if the trained model is safe and allowed for prediction. Get the state of the checker run together with the other state information with the get_state() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the state whenever you like\n",
    "print(run.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Finally, it's time to use the trained model to predict something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# get the latest model\n",
    "model = project.get_latest_model()\n",
    "\n",
    "# check DQ0 privacy clearing\n",
    "if model.predict_allowed:\n",
    "\n",
    "    # get numpy predict data\n",
    "    predict_data = model.X_test[:10]\n",
    "    \n",
    "    y_actual = model.y_test[:10]\n",
    "    y_actual = model.label_encoder.inverse_transform(np.ravel(y_actual))\n",
    "    \n",
    "    # let's visualize the pics\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(10):\n",
    "        plt.subplot(np.ceil(num_images_to_plot / 5), 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(predict_data[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(self.model.data_source.class_names[y_actual[i]])\n",
    "    plt.show()\n",
    "    \n",
    "    # call predict\n",
    "    run = model.predict(predict_data)\n",
    "\n",
    "    # wait for completion\n",
    "    run.wait_for_completion(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predict results\n",
    "y_pred = run.get_results()['predict']\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly assess how good the predictions of our model are by generating the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dq0.sdk.data.utils.plotting import compute_confusion_matrix\n",
    "\n",
    "y_pred = model.label_encoder.inverse_transform(np.ravel(y_pred))\n",
    "\n",
    "normalize=False # set to True to have the matrix entries normalized per row \n",
    "cm, labels_list = compute_confusion_matrix(y_actual, y_pred, normalize=normalize)\n",
    "\n",
    "if normalize:\n",
    "    fmt = '.2f'\n",
    "else:\n",
    "    fmt = 'd'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "if len(labels_list) > 10:\n",
    "    annot_kws = {'size': 6}  # reduce font size to avoid cluttering\n",
    "    xticks_rotation = '45'\n",
    "else:\n",
    "    annot_kws = None\n",
    "sns.heatmap(cm, ax=ax, annot=True, cbar=True, fmt=fmt, cmap=cmap,\n",
    "            annot_kws=annot_kws)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('Actual labels')\n",
    "ax.set_title(title)\n",
    "ax.xaxis.set_ticklabels(labels_list)\n",
    "ax.yaxis.set_ticklabels(labels_list)\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "# rotate the tick labels and set their alignment\n",
    "if xticks_rotation.lower() != 'horizontal'.lower():\n",
    "    for c_ax in [ax.get_xticklabels(), ax.get_yticklabels()]:\n",
    "        plt.setp(c_ax, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}