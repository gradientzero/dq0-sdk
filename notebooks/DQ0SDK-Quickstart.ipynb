{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept\n",
    "The two main structures to work with DQ0 quarantine via the DQ0 SDK are\n",
    "* Project - the current model environment, a workspace and directory the user can define models in. Project also provides access to trained models.\n",
    "* Experiment - the DQ0 runtime to execute training runs in the remote quarantine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the core classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dominic/Projects/dq0-sdk\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dq0-sdk api\n",
    "from dq0.sdk.cli import Project, Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "Projects act as the working environment for model development.\n",
    "Each project has a model directory with a .meta file containing the model uuid, attached data sources etc.\n",
    "Creating a project with `Project.create(name='model_1')` is equivalent to calling the DQ0 Cli command `dq0-cli project create model_1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQ0 SDK Demo\n",
    "## Prerequistes\n",
    "* Installed DQ0 SDK. Install with `pip install dq0-sdk`\n",
    "* Installed DQ0 CLI.\n",
    "* Proxy running and registered from the DQ0 CLI with `dq0-cli proxy add ...`\n",
    "* Valid session of DQ0. Log in with `dq0 user login`\n",
    "* Running instance of DQ0 CLI server: `dq0 server start`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully created new project: project_2\n"
     ]
    }
   ],
   "source": [
    "# create a project with name 'model_1'. Automatically creates the 'model_1' directory and changes to this directory.\n",
    "project = Project(name='model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a project\n",
    "Alternatively, you can load an existing project by first cd'ing into this directory and then call Project.load()\n",
    "This will read in the .meta file of this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../dq0-cli/census'\n",
      "/Users/dominic/Projects/dq0-sdk\n"
     ]
    }
   ],
   "source": [
    "%cd ../dq0-cli/census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: load a project from the current model directory\n",
    "project = Project.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2db5a563-3789-4601-a02d-98ed04ab5de6'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.project_uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "To execute DQ0 training commands inside the quarantine you define experiments for your projects.\n",
    "You can create as many experiments as you like for one project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment for project\n",
    "experiment = Experiment(project=project, name='experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and attach data source\n",
    "For new projects you need to attach a data source. Existing (loaded) projects usually already have data sources attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_uuid': 'ff16ffca-c5c1-4a41-9e88-3b5541eaf6cd',\n",
       " 'data_name': 'test2',\n",
       " 'data_type': 'sqlite',\n",
       " 'data_description': 'main db2',\n",
       " 'data_permissions': [''],\n",
       " 'data_usage': 89,\n",
       " 'created_at': 1605633820,\n",
       " 'updated_at': 1605634332}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get some info about available data sources\n",
    "sources = project.get_available_data_sources()\n",
    "\n",
    "# get info about the first source\n",
    "info = project.get_data_info(sources[0])\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'main db2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data description\n",
    "info['data_description']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, inspect the data column types including allowed values for feature generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print information about column types and values\n",
    "info['data_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, attach the dataset to our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully attached data to project\n"
     ]
    }
   ],
   "source": [
    "# attach the first dataset\n",
    "project.attach_data_source(sources[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "Working with DQ0 is basically about defining two functions:\n",
    "* setup_data() - called right before model training to prepare attached data sources\n",
    "* setup_model() - actual model definition code\n",
    "The easiest way to define those functions is to write them in the notebook (inline) and pass them to the project before calling deploy. Alternatively, the user can write the complete user_model.py to the project's directory.\n",
    "\n",
    "### Define fuctions inline\n",
    "First variant with functions passed to the project instance. Note that you need to define imports inline inside the functions as only those code blocks are replaced in the source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully set model code.\n"
     ]
    }
   ],
   "source": [
    "# define functions\n",
    "\n",
    "def setup_data():\n",
    "    # load input data\n",
    "    if self.data_source is None:\n",
    "        logger.error('No data source found')\n",
    "        return\n",
    "\n",
    "    data = self.data_source.read()\n",
    "\n",
    "    # read and preprocess the data\n",
    "    dataset_df = self.preprocess()\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train_df, X_test_df, y_train_ts, y_test_ts =\\\n",
    "        train_test_split(dataset_df.iloc[:, :-1],\n",
    "                         dataset_df.iloc[:, -1],\n",
    "                         test_size=0.33,\n",
    "                         random_state=42)\n",
    "    self.input_dim = X_train_df.shape[1]\n",
    "\n",
    "    # set data member variables\n",
    "    self.X_train = X_train_df\n",
    "    self.X_test = X_test_df\n",
    "    self.y_train = y_train_ts\n",
    "    self.y_test = y_test_ts\n",
    "    \n",
    "def setup_model():\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    # As an alternative, define the loss function with a string\n",
    "    self.epochs = 10\n",
    "    self.batch_size = 250\n",
    "    # self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "    self.optimizer = 'Adam'\n",
    "    self.num_microbatches = 250\n",
    "    self.metrics = ['accuracy']\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    self.model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(self.input_dim),\n",
    "        tf.keras.layers.Dense(10, activation='tanh'),\n",
    "        tf.keras.layers.Dense(10, activation='tanh'),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')])\n",
    "    \n",
    "def preprocess():\n",
    "    # columns\n",
    "    column_names_list = [\n",
    "        'lastname',\n",
    "        'firstname',\n",
    "        'age',\n",
    "        'workclass',\n",
    "        'fnlwgt',\n",
    "        'education',\n",
    "        'education-num',\n",
    "        'marital-status',\n",
    "        'occupation',\n",
    "        'relationship',\n",
    "        'race',\n",
    "        'sex',\n",
    "        'capital-gain',\n",
    "        'capital-loss',\n",
    "        'hours-per-week',\n",
    "        'native-country',\n",
    "        'income'\n",
    "    ]\n",
    "\n",
    "    # columns types list drawn from data source types information above.\n",
    "    columns_types_list = [\n",
    "        {\n",
    "            'name': 'age',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'workclass',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Private',\n",
    "                'Self-emp-not-inc',\n",
    "                'Self-emp-inc',\n",
    "                'Federal-gov',\n",
    "                'Local-gov',\n",
    "                'State-gov',\n",
    "                'Without-pay',\n",
    "                'Never-worked',\n",
    "                'Unknown'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'fnlwgt',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'education',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Bachelors',\n",
    "                'Some-college',\n",
    "                '11th',\n",
    "                'HS-grad',\n",
    "                'Prof-school',\n",
    "                'Assoc-acdm',\n",
    "                'Assoc-voc',\n",
    "                '9th',\n",
    "                '7th-8th',\n",
    "                '12th',\n",
    "                'Masters',\n",
    "                '1st-4th',\n",
    "                '10th',\n",
    "                'Doctorate',\n",
    "                '5th-6th',\n",
    "                'Preschool'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'education-num',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'marital-status',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Married-civ-spouse',\n",
    "                'Divorced',\n",
    "                'Never-married',\n",
    "                'Separated',\n",
    "                'Widowed',\n",
    "                'Married-spouse-absent',\n",
    "                'Married-AF-spouse'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'occupation',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Tech-support',\n",
    "                'Craft-repair',\n",
    "                'Other-service',\n",
    "                'Sales',\n",
    "                'Exec-managerial',\n",
    "                'Prof-specialty',\n",
    "                'Handlers-cleaners',\n",
    "                'Machine-op-inspct',\n",
    "                'Adm-clerical',\n",
    "                'Farming-fishing',\n",
    "                'Transport-moving',\n",
    "                'Priv-house-serv',\n",
    "                'Protective-serv',\n",
    "                'Armed-Forces',\n",
    "                'Unknown'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'relationship',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Wife',\n",
    "                'Own-child',\n",
    "                'Husband',\n",
    "                'Not-in-family',\n",
    "                'Other-relative',\n",
    "                'Unmarried'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'race',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'White',\n",
    "                'Asian-Pac-Islander',\n",
    "                'Amer-Indian-Eskimo',\n",
    "                'Other',\n",
    "                'Black'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'sex',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'Female',\n",
    "                'Male'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'name': 'capital-gain',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'capital-loss',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'hours-per-week',\n",
    "            'type': 'int'\n",
    "        },\n",
    "        {\n",
    "            'name': 'native-country',\n",
    "            'type': 'string',\n",
    "            'values': [\n",
    "                'United-States',\n",
    "                'Cambodia',\n",
    "                'England',\n",
    "                'Puerto-Rico',\n",
    "                'Canada',\n",
    "                'Germany',\n",
    "                'Outlying-US(Guam-USVI-etc)',\n",
    "                'India',\n",
    "                'Japan',\n",
    "                'Greece',\n",
    "                'South',\n",
    "                'China',\n",
    "                'Cuba',\n",
    "                'Iran',\n",
    "                'Honduras',\n",
    "                'Philippines',\n",
    "                'Italy',\n",
    "                'Poland',\n",
    "                'Jamaica',\n",
    "                'Vietnam',\n",
    "                'Mexico',\n",
    "                'Portugal',\n",
    "                'Ireland',\n",
    "                'France',\n",
    "                'Dominican-Republic',\n",
    "                'Laos',\n",
    "                'Ecuador',\n",
    "                'Taiwan',\n",
    "                'Haiti',\n",
    "                'Columbia',\n",
    "                'Hungary',\n",
    "                'Guatemala',\n",
    "                'Nicaragua',\n",
    "                'Scotland',\n",
    "                'Thailand',\n",
    "                'Yugoslavia',\n",
    "                'El-Salvador',\n",
    "                'Trinadad&Tobago',\n",
    "                'Peru',\n",
    "                'Hong',\n",
    "                'Holand-Netherlands',\n",
    "                'Unknown'\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    from dq0.sdk.data.preprocessing import preprocessing\n",
    "    import sklearn.preprocessing\n",
    "    import pandas as pd\n",
    "\n",
    "    if 'dataset' in globals():\n",
    "        # local testing mode\n",
    "        dataset = globals()['dataset']\n",
    "    else:\n",
    "        # get the input dataset\n",
    "        if self.data_source is None:\n",
    "            logger.error('No data source found')\n",
    "            return\n",
    "\n",
    "        # read the data via the attached input data source\n",
    "        dataset = self.data_source.read(\n",
    "            names=column_names_list,\n",
    "            sep=',',\n",
    "            skiprows=1,\n",
    "            index_col=None,\n",
    "            skipinitialspace=True,\n",
    "            na_values={\n",
    "                'capital-gain': 99999,\n",
    "                'capital-loss': 99999,\n",
    "                'hours-per-week': 99,\n",
    "                'workclass': '?',\n",
    "                'native-country': '?',\n",
    "                'occupation': '?'}\n",
    "        )\n",
    "\n",
    "    # drop unused columns\n",
    "    dataset.drop(['lastname', 'firstname'], axis=1, inplace=True)\n",
    "    column_names_list.remove('lastname')\n",
    "    column_names_list.remove('firstname')\n",
    "\n",
    "    # define target feature\n",
    "    target_feature = 'income'\n",
    "\n",
    "    # get categorical features\n",
    "    categorical_features_list = [\n",
    "        col['name'] for col in columns_types_list\n",
    "        if col['type'] == 'string']\n",
    "\n",
    "    # get categorical features\n",
    "    quantitative_features_list = [\n",
    "        col['name'] for col in columns_types_list\n",
    "        if col['type'] == 'int' or col['type'] == 'float']\n",
    "\n",
    "    # get arguments\n",
    "    approach_for_missing_feature = 'imputation'\n",
    "    imputation_method_for_cat_feats = 'unknown'\n",
    "    imputation_method_for_quant_feats = 'median'\n",
    "    features_to_drop_list = None\n",
    "\n",
    "    # handle missing data\n",
    "    dataset = preprocessing.handle_missing_data(\n",
    "        dataset,\n",
    "        mode=approach_for_missing_feature,\n",
    "        imputation_method_for_cat_feats=imputation_method_for_cat_feats,\n",
    "        imputation_method_for_quant_feats=imputation_method_for_quant_feats,  # noqa: E501\n",
    "        categorical_features_list=categorical_features_list,\n",
    "        quantitative_features_list=quantitative_features_list)\n",
    "\n",
    "    if features_to_drop_list is not None:\n",
    "        dataset.drop(features_to_drop_list, axis=1, inplace=True)\n",
    "\n",
    "    # get dummy columns\n",
    "    dataset = pd.get_dummies(dataset, columns=categorical_features_list, dummy_na=False)    \n",
    "\n",
    "    # unzip categorical features with dummies\n",
    "    categorical_features_list_with_dummies = []\n",
    "    for col in columns_types_list:\n",
    "        if col['type'] == 'string':\n",
    "            for value in col['values']:\n",
    "                categorical_features_list_with_dummies.append('{}_{}'.format(col['name'], value))\n",
    "\n",
    "    # add missing columns\n",
    "    missing_columns = set(categorical_features_list_with_dummies) - set(dataset.columns)\n",
    "    for col in missing_columns:\n",
    "        dataset[col] = 0\n",
    "        \n",
    "    # and sort the columns\n",
    "    dataset = dataset.reindex(sorted(dataset.columns), axis=1)\n",
    "\n",
    "    # Scale values to the range from 0 to 1 to be precessed by the neural network\n",
    "    dataset[quantitative_features_list] = sklearn.preprocessing.minmax_scale(dataset[quantitative_features_list])\n",
    "\n",
    "    # label target\n",
    "    y_ts = dataset[target_feature]\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    y_bin_nb = le.fit_transform(y_ts)\n",
    "    y_bin = pd.Series(index=y_ts.index, data=y_bin_nb)\n",
    "    dataset.drop([target_feature], axis=1, inplace=True)\n",
    "    dataset[target_feature] = y_bin\n",
    "\n",
    "    return dataset\n",
    "    \n",
    "# set model code in project\n",
    "project.set_model_code(setup_data=setup_data, setup_model=setup_model, preprocess=preprocess, parent_class_name='NeuralNetworkClassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions as source code\n",
    "Second variant, writing the complete model. Template can be retrieved by `!cat models/user_model.py` which is created by Project create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing models/user_model.py\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/user_model.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fe58d16f72f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/user_model.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nimport logging\\n\\nfrom dq0.sdk.models.tf import NeuralNetworkClassification\\n\\nlogger = logging.getLogger()\\n\\n\\nclass UserModel(NeuralNetworkClassification):\\n    \"\"\"Derived from dq0.sdk.models.tf.NeuralNetwork class\\n\\n    Model classes provide a setup method for data and model\\n    definitions.\\n    \"\"\"\\n    def __init__(self):\\n        super().__init__()\\n\\n    def setup_data(self):\\n        \"\"\"Setup data function. See code above...\"\"\"\\n        pass\\n\\n    def preprocess(self):\\n        \"\"\"Preprocess the data. See code above...\"\"\"\\n        pass\\n\\n    def setup_model(self):\\n        \"\"\"Setup model function See code above...\"\"\"\\n        pass\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/dq0/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dq0/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dq0/lib/python3.7/site-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/user_model.py'"
     ]
    }
   ],
   "source": [
    "%%writefile models/user_model.py\n",
    "\n",
    "import logging\n",
    "\n",
    "from dq0.sdk.models.tf import NeuralNetworkClassification\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class UserModel(NeuralNetworkClassification):\n",
    "    \"\"\"Derived from dq0.sdk.models.tf.NeuralNetwork class\n",
    "\n",
    "    Model classes provide a setup method for data and model\n",
    "    definitions.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def setup_data(self):\n",
    "        \"\"\"Setup data function. See code above...\"\"\"\n",
    "        pass\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Preprocess the data. See code above...\"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup_model(self):\n",
    "        \"\"\"Setup model function See code above...\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "After testing the model locally directly in this notebook, it's time to train it inside the DQ0 quarantine. This is done by calling experiment.train() which in turn calls the Cli commands `dq0-cli project deploy` and `dq0-cli model train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run started by job with uuid: 599d8521-2553-4e98-a164-ae5fca52ce5e\n"
     ]
    }
   ],
   "source": [
    "run = experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is executed asynchronously. You can wait for the run to complete or get the state with get_state:\n",
    "(TBD: in the future there could by a jupyter extension that shows the run progress in a widget.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for job to complete...\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "finished\n",
      "Job completed\n"
     ]
    }
   ],
   "source": [
    "# wait for completion\n",
    "run.wait_for_completion(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the run has completed you can retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 3, 'user_name': 'dv@gradient0.com', 'project_uuid': 'd08a001e-96dc-4dfc-9e68-568ad60855cd', 'project_name': 'project_2', 'commit_uuid': '42c591f8-5166-4445-a039-63c6a8798e5d', 'experiment_uuid': '283cee64-f583-4166-9d77-a838da8847dd', 'experiment_name': 'Default', 'job_uuid': '599d8521-2553-4e98-a164-ae5fca52ce5e', 'job_type': 'commit.run', 'job_logs': \"2020/11/20 14:29:18 INFO mlflow.projects: === Created directory /var/folders/45/kb4y2_5x5xqd14dtrp4bznpr0000gn/T/tmpd6fhbf1b for downloading remote URIs passed to arguments of type 'path' ===\\n2020/11/20 14:29:18 INFO mlflow.projects: === Running command 'python -m dq0.makedp my_param 123.66 --project-path /Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d --module-path None --data-src-uris /Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv --disable-DP False --l2-norm-clip 1.0 --module dq0.makedp --output-path /Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/model.h5 --data-type csv --log-name 599d8521-2553-4e98-a164-ae5fca52ce5e --log-path file:///Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/599d8521-2553-4e98-a164-ae5fca52ce5e.txt --noise-multiplier 1.1 --action train --budget 100 --log-level debug' in run with ID 'a3bda17b3f8f484c964bdd8095821dce' === \\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | [__KEYWORD_STARTED__] Model Trainer started with args: Namespace(_loglevel='debug', action='train', budget=100.0, data_src_uris='/Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv', data_type='csv', disable_DP='False', l2_norm_clip=1.0, log_name='599d8521-2553-4e98-a164-ae5fca52ce5e', log_path='file:///Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/599d8521-2553-4e98-a164-ae5fca52ce5e.txt', module_path='dq0.makedp', num_microbatches=None, output_path='/Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/model.h5', project_path='/Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d', target_epsilon=1)\\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | Start training of model dq0.makedp. [__KEYWORD_PROGRESS_001__]\\n2020-11-20T13:29:23Z | dq0 | DEBUG | \\n2020-11-20T13:29:23Z | dq0 | DEBUG | \\n2020-11-20T13:29:23Z | dq0 | DEBUG | PRNG seeded with value\\n2020-11-20T13:29:23Z | dq0 | DEBUG | 1\\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | Found one and using as instance: <my_model.MyModel object at 0x7faa0531ae90>\\n2020-11-20T13:29:23Z | dq0.makedp.train | DEBUG | Preparing data.\\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | Created data source instance: <dq0.sdk.data.text.csv.CSV object at 0x7faa05333ad0>\\n2020-11-20T13:29:23Z | dq0.makedp.train | DEBUG | Setting up data. [__KEYWORD_PROGRESS_010__]\\n2020-11-20T13:29:23Z | dq0.makedp.train | CRITICAL | Error while setting up data! [Errno 2] File b'/Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv' does not exist: b'/Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv'\\n2020/11/20 14:29:23 INFO mlflow.projects: === Run (ID 'a3bda17b3f8f484c964bdd8095821dce') succeeded ===\\n\", 'run_id': 'a3bda17b3f8f484c964bdd8095821dce', 'run_status': 'FINISHED', 'run_start_time': 1605878957990, 'run_end_time': 1605878963742, 'run_stage': 'active', 'params': [{'key': 'param2', 'value': '123.66'}, {'key': 'param1', 'value': 'my_param'}], 'tags': [{'key': 'mlflow.project.entryPoint', 'value': 'train_use_dq0_makedp'}]}\n"
     ]
    }
   ],
   "source": [
    "# get training results\n",
    "print(run.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After train dq0 will run the model checker to evaluate if the trained model is safe and allowed for prediction. Get the state of the checker run together with the other state information with the get_state() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 3, 'user_name': 'dv@gradient0.com', 'project_uuid': 'd08a001e-96dc-4dfc-9e68-568ad60855cd', 'project_name': 'project_2', 'commit_uuid': '42c591f8-5166-4445-a039-63c6a8798e5d', 'experiment_uuid': '283cee64-f583-4166-9d77-a838da8847dd', 'experiment_name': 'Default', 'job_uuid': '599d8521-2553-4e98-a164-ae5fca52ce5e', 'job_type': 'commit.run', 'job_logs': \"2020/11/20 14:29:18 INFO mlflow.projects: === Created directory /var/folders/45/kb4y2_5x5xqd14dtrp4bznpr0000gn/T/tmpd6fhbf1b for downloading remote URIs passed to arguments of type 'path' ===\\n2020/11/20 14:29:18 INFO mlflow.projects: === Running command 'python -m dq0.makedp my_param 123.66 --project-path /Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d --module-path None --data-src-uris /Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv --disable-DP False --l2-norm-clip 1.0 --module dq0.makedp --output-path /Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/model.h5 --data-type csv --log-name 599d8521-2553-4e98-a164-ae5fca52ce5e --log-path file:///Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/599d8521-2553-4e98-a164-ae5fca52ce5e.txt --noise-multiplier 1.1 --action train --budget 100 --log-level debug' in run with ID 'a3bda17b3f8f484c964bdd8095821dce' === \\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | [__KEYWORD_STARTED__] Model Trainer started with args: Namespace(_loglevel='debug', action='train', budget=100.0, data_src_uris='/Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv', data_type='csv', disable_DP='False', l2_norm_clip=1.0, log_name='599d8521-2553-4e98-a164-ae5fca52ce5e', log_path='file:///Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/599d8521-2553-4e98-a164-ae5fca52ce5e.txt', module_path='dq0.makedp', num_microbatches=None, output_path='/Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d/.out/model.h5', project_path='/Users/dominic/go/src/dq0-platform/__projects/d08a001e-96dc-4dfc-9e68-568ad60855cd/42c591f8-5166-4445-a039-63c6a8798e5d', target_epsilon=1)\\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | Start training of model dq0.makedp. [__KEYWORD_PROGRESS_001__]\\n2020-11-20T13:29:23Z | dq0 | DEBUG | \\n2020-11-20T13:29:23Z | dq0 | DEBUG | \\n2020-11-20T13:29:23Z | dq0 | DEBUG | PRNG seeded with value\\n2020-11-20T13:29:23Z | dq0 | DEBUG | 1\\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | Found one and using as instance: <my_model.MyModel object at 0x7faa0531ae90>\\n2020-11-20T13:29:23Z | dq0.makedp.train | DEBUG | Preparing data.\\n2020-11-20T13:29:23Z | dq0.makedp.train | INFO | Created data source instance: <dq0.sdk.data.text.csv.CSV object at 0x7faa05333ad0>\\n2020-11-20T13:29:23Z | dq0.makedp.train | DEBUG | Setting up data. [__KEYWORD_PROGRESS_010__]\\n2020-11-20T13:29:23Z | dq0.makedp.train | CRITICAL | Error while setting up data! [Errno 2] File b'/Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv' does not exist: b'/Users/dominic/go/src/dq0-platform/_data/census-processed/census.csv'\\n2020/11/20 14:29:23 INFO mlflow.projects: === Run (ID 'a3bda17b3f8f484c964bdd8095821dce') succeeded ===\\n\", 'run_id': 'a3bda17b3f8f484c964bdd8095821dce', 'run_status': 'FINISHED', 'run_start_time': 1605878957990, 'run_end_time': 1605878963742, 'run_stage': 'active', 'params': [{'key': 'param2', 'value': '123.66'}, {'key': 'param1', 'value': 'my_param'}], 'tags': [{'key': 'mlflow.project.entryPoint', 'value': 'train_use_dq0_makedp'}]}\n"
     ]
    }
   ],
   "source": [
    "# get the state whenever you like\n",
    "print(run.get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': <dq0.sdk.cli.project.Project at 0x7fb02d3d4350>,\n",
       " 'run_id': 'a3bda17b3f8f484c964bdd8095821dce',\n",
       " 'model_uuid': '',\n",
       " 'predict_allowed': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the model\n",
    "model = run.get_model()\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "DQ0SDKError",
     "evalue": "model location does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDQ0SDKError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-85dbad110235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# register the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/dq0-sdk/dq0/sdk/cli/model.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, run_id, model_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m         response = self.project.client.post(\n\u001b[1;32m     92\u001b[0m             routes.model.register, data=data)\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mcheckSDKResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_uuid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_uuid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model with uuid {} registered successfully'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_uuid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dq0-sdk/dq0/sdk/errors/errors.py\u001b[0m in \u001b[0;36mcheckSDKResponse\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDQ0SDKError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mDQ0SDKError\u001b[0m: model location does not exist"
     ]
    }
   ],
   "source": [
    "# register the model\n",
    "model.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Finally, it's time to use the trained model to predict something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully started predict job with uuid: c1ac64f1-6aa5-42bf-8cd7-80b791ba5cf3\n",
      "Waiting for job to complete...\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-db74c54ad12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# wait for completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/dq0-sdk/dq0/sdk/cli/runner/runner.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Waiting for job to complete...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;31m# refetch model or data job state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# check DQ0 privacy clearing\n",
    "if model.predict_allowed:\n",
    "\n",
    "    # create predict set\n",
    "    records = [\n",
    "        {\n",
    "            'lastname': 'some-lastname',\n",
    "            'firstname': 'some-firstname',\n",
    "            'age': 45,\n",
    "            'workclass':'Private',\n",
    "            'fnlwgt': 544091,\n",
    "            'education': 'HS-grad',\n",
    "            'education-num': 9,\n",
    "            'marital-status': 'Married-AF-spouse',\n",
    "            'occupation': 'Exec-managerial',\n",
    "            'relationship': 'Wife',\n",
    "            'race': 'White',\n",
    "            'sex': 'Female',\n",
    "            'capital-gain': 0,\n",
    "            'capital-loss': 0,\n",
    "            'hours-per-week': 25,\n",
    "            'native-country': 'United-States',\n",
    "            'income': '<=50K'\n",
    "        },\n",
    "        {\n",
    "            'lastname': 'some-lastname',\n",
    "            'firstname': 'some-firstname',\n",
    "            'age': 29,\n",
    "            'workclass': 'Federal-gov',\n",
    "            'fnlwgt': 162298,\n",
    "            'education': 'Masters',\n",
    "            'education-num': 14,\n",
    "            'marital-status': 'Married-civ-spouse',\n",
    "            'occupation': 'Exec-managerial',\n",
    "            'relationship': 'Husband',\n",
    "            'race': 'White',\n",
    "            'sex': 'Male',\n",
    "            'capital-gain': 34084,\n",
    "            'capital-loss': 0,\n",
    "            'hours-per-week': 70,\n",
    "            'native-country': 'United-States',\n",
    "            'income': '<=50K'\n",
    "        }\n",
    "    ]\n",
    "    dataset = pd.DataFrame.from_records(records)\n",
    "    \n",
    "    # drop target (included above only because of compatability with preprocess function)\n",
    "    dataset.drop(['income'], axis=1, inplace=True)\n",
    "\n",
    "    # load or get numpy predict data\n",
    "    # predict_data = np.load(‘X_demo_predict.npy’)\n",
    "    predict_data = dataset.to_numpy()\n",
    "\n",
    "    # call predict\n",
    "    #run = model.predict(predict_data)\n",
    "    run = model.predict(predict_data)\n",
    "\n",
    "    # wait for completion\n",
    "    run.wait_for_completion(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-57036ef1f9c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get predict results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'predict'"
     ]
    }
   ],
   "source": [
    "# get predict results\n",
    "print(run.get_results()['predict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
